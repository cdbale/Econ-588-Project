---
title: "588 Final Project"
author: "Cameron Bale"
date: "March 27, 2019"
output: github_document
---

I plan to model the number of units of cereal sold based on several independent variables. I will examine the ability
to make inference using the model based on different implementations of standard errors. The data is at the level of,
"How many units of a given upc were sold in a given store in a given week?"

***

Install and load packages. Increase memory limit.
```{r message = FALSE}
#install.packages('tidyverse')
#install.packages('AER')
#install.packages('plm')
#install.packages('lfe')
#install.packages('boot')
#install.packages('scales')
#install.packages('stargazer')
library(tidyverse)
library(lubridate)
library(lfe)
library(boot)
library(scales)
library(stargazer)
#memory.limit(size = 50000)
```

# Reading in the Data

Create a loop that:

* reads in the data for a given year (2010 - 2013)
* combines the movement data with the store file for the year
* filters for grocery stores in Utah
* joins with the upc file
* saves the full data file
```{r}
products <- read_tsv('products.tsv', quote = "")

years <- c(10, 11, 12, 13)

for (i in seq_along(years)) {

  move <- read_tsv(paste0('1344_20', years[i], '.tsv'))
  stores <- read_tsv(paste0('stores_20', years[i], '.tsv'), guess_max = 200000)

  full <- move %>%
    inner_join(stores, by = 'store_code_uc') %>%
    filter(channel_code == 'F' & fips_state_descr == 'UT') %>%
    inner_join(products, by = 'upc')

  save(full, file = paste0('full_', years[i], '.RData'))

  rm(move, stores, full)

}
```

Load data for all four years and combine.
```{r}
full_data <- tibble()

for (i in seq_along(years)) {
  
  load(paste0('full_', years[i], '.RData'))
  
  full_data <- full_data %>%
    bind_rows(full)
  
}

rm(full)
```

# Data Cleaning

View variable types.
```{r}
str(full_data)
```

Coercing upc and store zip code to proper data types.
```{r}
full_data$upc <- as.numeric(full_data$upc)
full_data$store_zip3 <- as.numeric(full_data$store_zip3)
```

View summary of continuous, independent variables.
```{r}
full_data %>%
  select(price, units) %>%
  summary()
```
The price variable has some outliers in the max. No box of cereal costs 279, I'm assuming it must be a case that 
was purchased, but I'm going to drop anything over 12 dollars for this analysis. The units variable is probably skewed
right.

Calculate 0.0001 and 0.9999 quantiles of data to use to remove outliers.
```{r}
price_quantiles <- quantile(full_data$price, probs = c(0.0001, 0.9999))
unit_quantiles <- quantile(full_data$units, probs = c(0.0001, 0.9999))
```

Filter for units contained within the 1st and 99th quantiles of price and units sold.
```{r}
full_data <- full_data %>%
  filter(price > price_quantiles[1] & price < price_quantiles[2],
         units > unit_quantiles[1] & units < unit_quantiles[2])
```

Convert week_end into date format, and remove observations that have missing values.
```{r}
full_data <- full_data %>%
  mutate(week_end = ymd(week_end))
```

View histogram of units sold.
```{r}
full_data %>%
  ggplot(aes(x = units)) +
  geom_histogram()
```
This seems pretty skewed so lets transform it using a natural log.

View histogram of natural log of units sold.
```{r}
full_data %>%
  ggplot(aes(x = log(units))) +
  geom_histogram()
```
This looks a bit better.

View histogram of price.
```{r}
full_data %>%
  ggplot(aes(x = price)) +
  geom_histogram()
```
This looks pretty good.

Let's create a log version of units sold.
```{r}
full_data <- full_data %>%
  mutate(lunits = log(units)) %>%
  mutate(size = size1_amount)
```

Load in google trends search data for keyword 'cereal'.
```{r}
trends <- read_csv('multiTimeline.csv') %>%
  mutate(week_end = mdy(week_end) + 6)
```

Filter the trend data so that dates line up.
```{r}
trends <- trends %>%
  filter(week_end < '2014-01-04' & week_end > '2009-12-26')
```

Join trend data to full data.
```{r}
full_data <- full_data %>%
  left_join(trends, by = 'week_end')
```

Save data for future use.
```{r}
save(full_data, file = 'full_data.RData')
```

Load data.
```{r}
load('full_data.RData')
```

# Model

I want to include the following variables to explain the number of units sold;

* **price** : what price was the product sold at.
* **feature** : All retailer advertisements found in local newspapers, free standing inserts (FSIs), and
free standing circulars, and may also include online ads from the retailer's website. The vast
majority of featured items will include a price discount, but they don't have to. Features include
Major Ads (which typically include an image as well as the price of an item), Line Ads (only has
the name and price of the item), and retailer coupons that can be redeemed at the register.
* **display** : Display - a secondary location of an item in the store that is non-permanent and intended for
merchandising purposes. Displays are located in the Store Lobby, Front of Store, End of Aisle, In
Aisle, or Back of Store. Displayed items may or may not have an associated price decrease.
* **size** : size in oz of product

and depending on the model, I'll include fixed effects/clustering/random effects, etc. (tbd) for the following:

* **store_code_uc** : unique store identifier
* **week_end** : control for seasonality using google trends? identifies the date
* **year** : gives the year
* **retailer_code** : unique retailer identifier
* **store_zip** : identifies the first three digits of store zip code
* **fips_county** : identifies the county a store is located in

Select variables of interest.
```{r}
full_data <- full_data %>%
  select(upc,
         brand_code_uc,
         week_end,
         store_code_uc, 
         retailer_code, 
         fips_county_descr,
         units,
         lunits,
         price,
         feature, 
         display) %>%
  drop_na() %>%  
  mutate(f_upc = as_factor(upc), 
         f_store_code_uc = as_factor(as.character(store_code_uc)),
         f_week_end = as_factor(as.character(week_end)),
         f_fips_county_descr = as_factor(fips_county_descr),
         f_brand_code_uc = as_factor(as.character(brand_code_uc)),
         f_retailer_code = as_factor(as.character(retailer_code)))
```

Provide table of data.
```{r}
top10 <- full_data[1:10,]
stargazer(top10, summary = FALSE, out = 'data_table.html')
```

Visualize data.
```{r}
full_data %>%
  ggplot(aes(x = price, y = lunits)) +
  geom_point() +
  labs(x = 'Price',
       y = 'Log Units',
       title = 'Natural Log of Units Sold Against Price')
```

Fixed effects model with regular standard errors.
```{r}
fe_model <- full_data %>%
  felm(lunits ~ price + feature + display | 
                f_upc + f_brand_code_uc + f_store_code_uc + f_retailer_code + f_week_end + f_fips_county_descr, 
       data = ., exactDOF = 'rM')

fe_sum <- summary(fe_model)
summary(fe_model)
```

Output regression table for regular model.
```{r}
stargazer(fe_model, title = 'Regression Results', out = 'reg_results.html')
```

Interpretable coefficients.
```{r}
int_coeffs <- (exp(fe_model$coefficients) - 1) * 100
stargazer(int_coeffs, title = 'Transformed Coefficients', out = 'int_coeffs.html')
```

Store regular standard errors.
```{r}
reg_errors <- fe_model$se
```

Calculate robust standard errors (independent but not identical)
```{r}
(robust_summary <- summary(fe_model, robust = TRUE))
robust_errors <- robust_summary$coefficients[,2]
```

Perform bootstrapping to compare standard errors to robust.
```{r message = FALSE}
# function to obtain regression weights 
bs <- function(formula, data, indices) {
  d <- data[indices,] # allows boot to select sample 
  fit <- felm(formula, data=d, exactDOF = 'rM')
  return(coef(fit)) 
} 
# bootstrapping with 1000 replications 
results <- boot(data=full_data, statistic=bs, 
   R=1000, formula=lunits ~ price + feature + display | 
                f_upc + f_brand_code_uc + f_store_code_uc + f_retailer_code + f_week_end + f_fips_county_descr)

bs_dists <- as_tibble(results$t, .name_repair = "universal")

names(bs_dists) <- c('Price', 'Feature', 'Display')

bs_dists <- bs_dists %>%
  gather(key = 'variable', value = 'estimate')

price_ests <- bs_dists %>%
  filter(variable == 'Price')

price_qs <- quantile(price_ests$estimate, c(0.025, 0.975))

price_ests %>%
  ggplot(aes(x = estimate)) +
  geom_density() +
  geom_vline(xintercept = price_qs, color = 'blue') +
  geom_vline(xintercept = results$t0[1], color = 'red') +
  labs(title = 'Bootstrapped Price Coefficient Estimates',
       x = 'Estimate',
       y = 'Density')
```

Store bootstrapped standard errors.
```{r}
bs_ses = sapply(data.frame(results$t), sd)
```

Cluster correct standard errors at the upc level.
```{r}
upc_cluster_fe_model <- full_data %>%
  felm(lunits ~ price + feature + display | 
                f_upc + f_brand_code_uc + f_store_code_uc + f_retailer_code + f_week_end + f_fips_county_descr | 0 |
                f_upc, 
       data = ., exactDOF = 'rM')

upc_cluster_fe_sum <- summary(upc_cluster_fe_model)
upc_cluster_fe_sum
```

Store standard errors from regression with standard errors clustered at the upc level.
```{r}
upc_cluster_se <- upc_cluster_fe_sum$coefficients[,2]
```

Cluster correct standard errors at the upc and store level.
```{r}
store_upc_cluster_fe_model <- full_data %>%
  felm(lunits ~ price + feature + display | 
                f_upc + f_brand_code_uc + f_store_code_uc + f_retailer_code + f_week_end + f_fips_county_descr | 0 |
                f_upc + f_store_code_uc, 
       data = ., exactDOF = 'rM')

store_upc_cluster_fe_sum <- summary(store_upc_cluster_fe_model)
store_upc_cluster_fe_sum
```

Store standard errors cluster corrected at the store and upc level.
```{r}
store_upc_cluster_se <- store_upc_cluster_fe_sum$coefficients[,2]
```

Create a table of standard errors.
```{r}
se_vals <- tibble(reg_errors,
       robust_errors,
       upc_cluster_se,
       store_upc_cluster_se)

reg_errors <- enframe(reg_errors, name = "Variable", value = "Normal")
robust_errors <- enframe(robust_errors, name = "Variable", value = "Robust")
upc_cluster_se <- enframe(upc_cluster_se, name = "Variable", value = "Cluster: UPC")
store_upc_cluster_se <- enframe(store_upc_cluster_se, name = "Variable", value = "Cluster: UPC + Store")

bs_df <- tibble(
  Variable = c('price', 'feature', 'display'),
  Bootstrapped = bs_ses
)

errors <- reg_errors %>%
  left_join(robust_errors, by = "Variable") %>%
  left_join(bs_df, by = "Variable") %>%
  left_join(upc_cluster_se, by = "Variable") %>%
  left_join(store_upc_cluster_se, by = "Variable")

(errors <- errors %>%
  mutate_if(is.numeric, ~ round(., digits = 4)))
```

```{r}
stargazer(errors, summary = FALSE, out = 'error_table.html')
```

Outputting regression results in one table.
```{r}
robust_se <- robust_summary$coefficients[,2]

stargazer(fe_model, fe_model, fe_model, upc_cluster_fe_model, store_upc_cluster_fe_model,
          out = 'combined_table.html',
          se = list(NULL, robust_se, as.vector(bs_ses)),
          digits = 5,
          omit.stat = c('ser', 'rsq'),
          covariate.labels = c('Price', 'Feature', 'Display'),
          dep.var.caption = "",
          column.labels = c('Regular', 
                            'Robust', 
                            'BS', 
                            'UPC Cluster', 
                            'UPC/Store Cluster'),
          dep.var.labels.include = FALSE)
```





















